---
layout: post
title: Bad metrics
date: 2013-11-15 19:33:06.000000000 +00:00
---
<p>Quantifying research quality and impact is a tricky issue. <a href="http://en.wikipedia.org/wiki/Altmetrics">"Altmetrics are new metrics proposed as an alternative to the widely used journal impact factor and personal citation indices like the <i>h</i>-index."</a> Instead of waiting for your peers to read and cite your work, you can now get instant kudos from retweets and Facebook likes.</p>
<p><img class="size-full wp-image-712 aligncenter" alt="AltM" src="{{ site.baseurl }}/assets/2013/11/altm.png" width="358" height="168" />Of course this can be a useful tool for tracking engagement (or massaging your ego), but not as a serious metric for quality or impact as many are now proposing (and some institutions implementing). I was disappointed to receive an email this week from the journal <a href="http://pubs.rsc.org/en/Content/ArticleLanding/2012/EE/C2EE22019A#!divMetrics">Energy &amp; Environmental Science</a> ranking recent publications by the arbitrary numbers given above.</p>
<p>Some potential flaws (for better worded opinions: [<a href="http://www.nature.com/nature/journal/v494/n7436/full/494176d.html">1</a>],[<a href="http://biij.org.uk/system/index.php/biij/article/viewArticle/396">2</a>]):</p>
<ul>
<li><em>Open to manipulation.</em> If science was a popularity contest, then virtually every major breakthrough would have been forgotten. Most Nobel laureates have a story of how their pioneering work was rejected for publication in a top-tier journal or poorly received by their peers. The danger here is aggressive marketing, e.g. a legion of university minions spamming all forms of social media or coercing students and alumni to "support" their academics. Similar to the music industry, the crowd pleasers from big institutions would come out on top, while real science could be driven underground (although I would be interested to experience <a href="http://en.wikipedia.org/wiki/No_wave">no wave</a> chemistry).</li>
<li><em>Encouraging exaggeration. </em>As press offices fight for attention, press releases are becoming increasingly misleading. In the field of solar cell research, paradigms are apparently being shifted multiple times per week, while there is rarely an actual increase in efficiency or a change in architecture. Real progress takes time, while inflated claims gather clicks. Maybe I should just stop looking at <a href="http://www.sciencedaily.com/news/matter_energy/chemistry/">Science Daily</a>.</li>
<li><em>Arbitrary weightings.</em> All citations are created equal, but does a one-click "retweet" or "like", imply that someone has read, appreciated or even opened the paper? A tweet from my mum should count double of course.</li>
</ul>
<p>It is important to see research metrics evolve, but that fact that a company can produce a pretty graph doesn't make it any more relevant. <em><a href="http://www.youtube.com/watch?v=IFgRoE5aQBY">Never Mind What's Been Selling, It's What You're Buying.</a></em></p>
